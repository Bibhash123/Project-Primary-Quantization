{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bibhash123/Project-Primary-Quantization/blob/main/experiments/Primary_Quantization_Third_Quant_Densenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "YQxHrBRvb0tj",
        "outputId": "b7a2baf9-d412-4907-d133-db0457e086fc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ee70f13a-a830-425a-a64f-80d44c7e7511\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ee70f13a-a830-425a-a64f-80d44c7e7511\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Downloading tondidataset.zip to /content\n",
            " 99% 574M/581M [00:04<00:00, 159MB/s]\n",
            "100% 581M/581M [00:04<00:00, 149MB/s]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "_ = files.upload()\n",
        "!mkdir ~/.kaggle/\n",
        "!cp kaggle.json ~/.kaggle/kaggle.json\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!pip install -q kaggle\n",
        "!kaggle datasets download -d \"bibhash123/tondidataset\"\n",
        "!unzip -q tondidataset.zip -d \"/content/Data/\"\n",
        "!rm -r tondidataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88LQFiMRY1YP",
        "outputId": "b604feba-9bfc-42c7-9c8a-0291ce344f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password: ··········\n",
            "Cloning into 'B.Tech-Project'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 59 (delta 20), reused 21 (delta 5), pack-reused 11\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n",
            "Cloning into 'CnnJpegPrimaryQuantizationEstimation'...\n",
            "remote: Enumerating objects: 459, done.\u001b[K\n",
            "remote: Counting objects: 100% (459/459), done.\u001b[K\n",
            "remote: Compressing objects: 100% (412/412), done.\u001b[K\n",
            "remote: Total 459 (delta 40), reused 430 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (459/459), 11.67 MiB | 15.05 MiB/s, done.\n",
            "Resolving deltas: 100% (40/40), done.\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "!git config --global user.email = \"bibhashp.das@gmail.com\"\n",
        "user = \"Bibahsh123\"\n",
        "password = getpass(\"Password: \")\n",
        "!git clone https://$user:$password@github.com/Bibhash123/B.Tech-Project.git\n",
        "!git clone https://github.com/andreacos/CnnJpegPrimaryQuantizationEstimation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9PGxNw2uUXY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj9xM-YVb5p1"
      },
      "outputs": [],
      "source": [
        "train_files = pd.read_csv(\"/content/Data/train.csv\",sep=\";\",header=None,\n",
        "                         names=['idx', 'filenames', 'quality1', 'quality2', 'software', 'labels',\n",
        "                                'shift_r', 'shift_c']\n",
        "                         )\n",
        "trn,val = train_test_split(train_files,test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m2rPxZI6b-N-"
      },
      "outputs": [],
      "source": [
        "def preprocess_input(im_file, target_size, scale=255.):\n",
        "    \"\"\" \n",
        "        Read image and (eventually) scale data\n",
        "        Arguments:\n",
        "            im_file     : input image file\n",
        "            target_size : output size of the image (height, width)\n",
        "            scale       : pixel scaling value\n",
        "        Returns: The image\n",
        "    \"\"\"\n",
        "    file_bytes = tf.io.read_file(im_file)\n",
        "    img = tf.image.decode_png(file_bytes, channels = 0)\n",
        "    # Normalize and Resize\n",
        "    if img.shape != target_size:\n",
        "        img = tf.image.resize(img, target_size)\n",
        "    img = tf.cast(img/scale, tf.float32)\n",
        "    return img\n",
        "  \n",
        "def string2Q(s, size=(8, 8), flatten=True):\n",
        "    \"\"\" Converts a comma separated string to a matrix.\n",
        "        Keyword arguments:\n",
        "        sq : input string\n",
        "        size : output matrix size\n",
        "    \"\"\"\n",
        "    if flatten:\n",
        "        return tf.strings.to_number(tf.strings.split(s,','),out_type=tf.int32)\n",
        "    else:\n",
        "        return tf.reshape(tf.strings.to_number(tf.strings.split(s,','),out_type=tf.int32),size)\n",
        "        \n",
        "def get_label(im_label):\n",
        "    return string2Q(im_label)[:15]\n",
        "\n",
        "def getQFRange(qf1):\n",
        "  return K.stack([qf1-5,qf1,qf1+5],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jM6Xk0ScBH2"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "def build_decoder(is_labelled):\n",
        "  def if_labelled(path,label, target_size):\n",
        "    image = preprocess_input(path,target_size)\n",
        "    out_img = K.concatenate([image-tf.image.adjust_jpeg_quality(image,qf) for qf in [60,65,70,75,80,85,90,95,98]],axis=-1)\n",
        "    label = get_label(label)\n",
        "    # qf = getQFRange(qf1)\n",
        "    return out_img,label\n",
        "  \n",
        "  return if_labelled if is_labelled else preprocess_input\n",
        "\n",
        "def create_dataset(df, batch_size = 32, is_labelled = False, repeat = False, shuffle = False, batch=False, cache=False):\n",
        "    decode_fn = build_decoder(is_labelled)\n",
        "    \n",
        "    # Create Dataset\n",
        "    if is_labelled:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((df['filenames'].values,df[\"labels\"].values))\n",
        "    else:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((df['filenames'].values))\n",
        "\n",
        "    dataset = dataset.map(partial(decode_fn,target_size=(64,64)), num_parallel_calls = AUTOTUNE)\n",
        "    dataset = dataset.cache(\"\") if cache else dataset\n",
        "    dataset = dataset.repeat() if repeat else dataset\n",
        "    dataset = dataset.shuffle(1024, reshuffle_each_iteration = True) if shuffle else dataset\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True) if batch else dataset\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def getX(X,Y):\n",
        "  return X\n",
        "def getY(X,Y):\n",
        "  return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vaev-NPcD5V"
      },
      "outputs": [],
      "source": [
        "train_set = create_dataset(trn, batch_size = 32, is_labelled = True, repeat = True, \n",
        "                          shuffle = True, batch=True,cache=False)\n",
        "val_set = create_dataset(val, batch_size = 32, is_labelled = True, repeat = False, \n",
        "                          shuffle = False, batch=True,cache=False)\n",
        "Y_val = val_set.map(getY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilfw8w6wzWYy"
      },
      "outputs": [],
      "source": [
        "# def buildModel(input_shape=(64,64,9),qfe_layers=1):\n",
        "#   inp = L.Input(shape=input_shape)\n",
        "\n",
        "#   backbone = tf.keras.applications.DenseNet121(include_top=False, \n",
        "#                                                weights=None, \n",
        "#                                                input_shape=(64,64,9))\n",
        "#   out = backbone(inp)\n",
        "#   out = L.Flatten()(out)\n",
        "#   out = L.Dense(32, activation='relu')(out)\n",
        "#   out = L.Dense(15, activation='linear', name='coeff')(out)\n",
        "\n",
        "#   model = tf.keras.Model(inputs=inp,outputs= out)\n",
        "#   model.compile(loss=tf.keras.losses.LogCosh(), optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),run_eagerly=True)\n",
        "#   return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UW2q8ncm9gnv",
        "outputId": "45fe27ca-b1a1-4c71-a50b-c00b59668ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating DenseNet\n",
            "#############################################\n",
            "Dense blocks: 3\n",
            "Layers per dense block: [6, 6, 6]\n",
            "#############################################\n"
          ]
        }
      ],
      "source": [
        "from densenet import DenseNet\n",
        "K.clear_session()\n",
        "with tf.device('/GPU:0'):\n",
        "  model,_ = DenseNet(input_shape = (64,64,9), nb_classes = 15, depth=24)\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate = 1e-5)\n",
        "  model.compile(loss = tf.keras.losses.LogCosh(), optimizer = opt, metrics=  ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMPjl1-91PYG"
      },
      "outputs": [],
      "source": [
        "# K.clear_session()\n",
        "# with tf.device('/GPU:0'):\n",
        "#   model = buildModel()\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-SJ68Ls1hhp",
        "outputId": "2891540b-b034-4afe-9c59-932cf39c3478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "6075/6075 [==============================] - 522s 83ms/step - loss: 3.6883 - accuracy: 0.6573 - val_loss: 2.6871 - val_accuracy: 0.7640\n",
            "Epoch 2/40\n",
            "6075/6075 [==============================] - 505s 83ms/step - loss: 2.4947 - accuracy: 0.7771 - val_loss: 2.3770 - val_accuracy: 0.7690\n",
            "Epoch 3/40\n",
            "6075/6075 [==============================] - 504s 83ms/step - loss: 2.3545 - accuracy: 0.7776 - val_loss: 2.3572 - val_accuracy: 0.7682\n",
            "Epoch 4/40\n",
            "6075/6075 [==============================] - 521s 86ms/step - loss: 2.2775 - accuracy: 0.7771 - val_loss: 2.3764 - val_accuracy: 0.7632\n",
            "Epoch 5/40\n",
            "6075/6075 [==============================] - 504s 83ms/step - loss: 2.2172 - accuracy: 0.7774 - val_loss: 2.1500 - val_accuracy: 0.7693\n",
            "Epoch 6/40\n",
            "6075/6075 [==============================] - 503s 83ms/step - loss: 2.1600 - accuracy: 0.7773 - val_loss: 2.0957 - val_accuracy: 0.7696\n",
            "Epoch 7/40\n",
            "6075/6075 [==============================] - 521s 86ms/step - loss: 2.1083 - accuracy: 0.7777 - val_loss: 2.0512 - val_accuracy: 0.7692\n",
            "Epoch 8/40\n",
            "6075/6075 [==============================] - 504s 83ms/step - loss: 2.0641 - accuracy: 0.7773 - val_loss: 2.1311 - val_accuracy: 0.7717\n",
            "Epoch 9/40\n",
            "6075/6075 [==============================] - 521s 86ms/step - loss: 2.0204 - accuracy: 0.7779 - val_loss: 1.9398 - val_accuracy: 0.7713\n",
            "Epoch 10/40\n",
            "6075/6075 [==============================] - 522s 86ms/step - loss: 1.9903 - accuracy: 0.7772 - val_loss: 1.9414 - val_accuracy: 0.7722\n",
            "Epoch 11/40\n",
            "6075/6075 [==============================] - 522s 86ms/step - loss: 1.9569 - accuracy: 0.7774 - val_loss: 1.9030 - val_accuracy: 0.7709\n",
            "Epoch 12/40\n",
            "6075/6075 [==============================] - 521s 86ms/step - loss: 1.9337 - accuracy: 0.7768 - val_loss: 1.9409 - val_accuracy: 0.7719\n",
            "Epoch 13/40\n",
            "6075/6075 [==============================] - 521s 86ms/step - loss: 1.9066 - accuracy: 0.7763 - val_loss: 1.8807 - val_accuracy: 0.7705\n",
            "Epoch 14/40\n",
            "6075/6075 [==============================] - 522s 86ms/step - loss: 1.8836 - accuracy: 0.7764 - val_loss: 1.8234 - val_accuracy: 0.7708\n",
            "Epoch 15/40\n",
            "6075/6075 [==============================] - 521s 86ms/step - loss: 1.8660 - accuracy: 0.7762 - val_loss: 1.8396 - val_accuracy: 0.7708\n",
            "Epoch 16/40\n",
            "6075/6075 [==============================] - 504s 83ms/step - loss: 1.8440 - accuracy: 0.7759 - val_loss: 1.8285 - val_accuracy: 0.7689\n",
            "Epoch 17/40\n",
            "6075/6075 [==============================] - 521s 86ms/step - loss: 1.8289 - accuracy: 0.7754 - val_loss: 1.7745 - val_accuracy: 0.7675\n",
            "Epoch 18/40\n",
            "6075/6075 [==============================] - 504s 83ms/step - loss: 1.8134 - accuracy: 0.7758 - val_loss: 1.9015 - val_accuracy: 0.7660\n",
            "Epoch 19/40\n",
            "6075/6075 [==============================] - 503s 83ms/step - loss: 1.7939 - accuracy: 0.7757 - val_loss: 1.7518 - val_accuracy: 0.7661\n",
            "Epoch 20/40\n",
            "6075/6075 [==============================] - 520s 86ms/step - loss: 1.7791 - accuracy: 0.7758 - val_loss: 1.7931 - val_accuracy: 0.7694\n",
            "Epoch 21/40\n",
            "6075/6075 [==============================] - 520s 86ms/step - loss: 1.7638 - accuracy: 0.7760 - val_loss: 1.6968 - val_accuracy: 0.7669\n",
            "Epoch 22/40\n",
            "6075/6075 [==============================] - 521s 86ms/step - loss: 1.7542 - accuracy: 0.7764 - val_loss: 1.7301 - val_accuracy: 0.7675\n",
            "Epoch 23/40\n",
            "6075/6075 [==============================] - 522s 86ms/step - loss: 1.7381 - accuracy: 0.7765 - val_loss: 1.7409 - val_accuracy: 0.7692\n",
            "Epoch 24/40\n",
            "6075/6075 [==============================] - 527s 87ms/step - loss: 1.7252 - accuracy: 0.7759 - val_loss: 1.6601 - val_accuracy: 0.7702\n",
            "6075/6075 [==============================] - 527s 87ms/step - loss: 1.7252 - accuracy: 0.7759 - val_loss: 1.6601 - val_accuracy: 0.7702\n",
            "Epoch 25/40\n",
            "   1/6075 [..............................] - ETA: 11:43 - loss: 1.6701 - accuracy: 0.6875Epoch 25/40\n",
            "6075/6075 [==============================] - 529s 87ms/step - loss: 1.7120 - accuracy: 0.7761 - val_loss: 1.6977 - val_accuracy: 0.7666\n",
            "6075/6075 [==============================] - 529s 87ms/step - loss: 1.7120 - accuracy: 0.7761 - val_loss: 1.6977 - val_accuracy: 0.7666\n",
            "Epoch 26/40\n",
            "   1/6075 [..............................] - ETA: 12:59 - loss: 1.7331 - accuracy: 0.7188Epoch 26/40\n",
            "  69/6075 [..............................] - ETA: 8:04 - loss: 1.6958 - accuracy: 0.7740\n",
            "[INFO] Interrupted Training\n",
            "\n",
            "[INFO] Interrupted Training\n",
            "[INFO] Obtaining Predictions\n",
            "[INFO] Obtaining Predictions\n"
          ]
        }
      ],
      "source": [
        "ckpt = tf.keras.callbacks.ModelCheckpoint('model.hdf5', monitor = 'val_loss', mode='min',\n",
        "                                          save_best_only = True, save_weights_only = True)\n",
        "es = tf.keras.callbacks.EarlyStopping(patience = 7, monitor = 'val_loss', mode='min',\n",
        "                                      restore_best_weights=True)\n",
        "try:\n",
        "  # model.load_weights('last_trained.hdf5')\n",
        "  model.fit(train_set,\n",
        "            epochs = 40,\n",
        "            steps_per_epoch = (trn.shape[0]//32),\n",
        "            validation_data = val_set,\n",
        "            callbacks = [ckpt,es],\n",
        "            initial_epoch=0\n",
        "            )\n",
        "except KeyboardInterrupt:\n",
        "  print(\"\\n[INFO] Interrupted Training\")\n",
        "  model.save_weights('last_trained.hdf5')\n",
        "print('[INFO] Obtaining Predictions')\n",
        "model.load_weights('model.hdf5')\n",
        "pred = model.predict(val_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zs0sf_bDYeOG"
      },
      "outputs": [],
      "source": [
        "model.load_weights('model.hdf5')\n",
        "# pred = model.predict(val_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHeIVj_Zue7_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "326ab0e3-3502-42d3-90ac-0ac8c6fe4e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape Y:  (21600, 15)\n",
            "Accuracy = 0.2098\n",
            "RMSE = 6.4564\n",
            "Shape Y:  (21600, 15)\n",
            "Accuracy = 0.2098\n",
            "RMSE = 6.4564\n"
          ]
        }
      ],
      "source": [
        "y = np.array(list(Y_val.unbatch().as_numpy_iterator()))\n",
        "print(\"Shape Y: \",y.shape)\n",
        "print(\"Accuracy = {:.4f}\".format(np.sum(np.round(pred)==y)/(15*y.shape[0])))\n",
        "print(\"RMSE = {:.4f}\".format(np.sum(np.square(y - pred)) / (y.shape[0]*15)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(list(Y_val.unbatch().as_numpy_iterator()))\n",
        "print(\"Shape Y: \",y.shape)\n",
        "print(\"Accuracy = {:.4f}\".format(np.sum(pred.astype(int)==y)/(15*y.shape[0])))\n",
        "print(\"RMSE = {:.4f}\".format(np.sum(np.square(y - pred)) / (y.shape[0]*15)))"
      ],
      "metadata": {
        "id": "41aR62GpbuCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc5c88d-eb36-4ca5-8f70-5cf411a177b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape Y:  (21600, 15)\n",
            "Accuracy = 0.1981\n",
            "RMSE = 6.4564\n",
            "Shape Y:  (21600, 15)\n",
            "Accuracy = 0.1981\n",
            "RMSE = 6.4564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAGtIBnjONfo",
        "outputId": "a657a7b8-cd38-482f-c4a9-846f3c7ed2b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/B.Tech-Project\n",
            "[main b9ff630] added model\n",
            " 2 files changed, 0 insertions(+), 0 deletions(-)\n",
            " rewrite Experiments/last_trained.hdf5 (84%)\n",
            " rewrite Experiments/model.hdf5 (84%)\n",
            "Counting objects: 5, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects: 100% (5/5), done.\n",
            "Writing objects: 100% (5/5), 7.57 MiB | 8.70 MiB/s, done.\n",
            "Total 5 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/Bibhash123/B.Tech-Project.git\n",
            "   9b3621b..b9ff630  main -> main\n"
          ]
        }
      ],
      "source": [
        "!cp \"/content/model.hdf5\" \"/content/B.Tech-Project/Experiments/\"\n",
        "!cp \"/content/last_trained.hdf5\" \"/content/B.Tech-Project/Experiments/\"\n",
        "%cd \"/content/B.Tech-Project/\"\n",
        "!git add .\n",
        "!git commit -m \"added model\"\n",
        "!git push origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2gesu_-KECR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfHvAAx4PcOG",
        "outputId": "91d16d4e-8c5e-4f78-ecf3-189946749cf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-16 08:21:22.420067: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Creating DenseNet\n",
            "#############################################\n",
            "Dense blocks: 3\n",
            "Layers per dense block: [6, 6, 6]\n",
            "#############################################\n",
            "Found 6000 images and 6000 labels in /content/Data/test.csv with filter (60, 90)\n",
            "Estimating Quantization Matrix: 100% 6000/6000 [24:07<00:00,  4.15it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "QF1 = 60 QF2 = 90\n",
            "--------------------------------------------------------------------------------\n",
            "Test average MSE: 14.5202\n",
            "Test average normalised MSE: 0.0954\n",
            "Test accuracy: 0.0655\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Found 6000 images and 6000 labels in /content/Data/test.csv with filter (65, 90)\n",
            "Estimating Quantization Matrix: 100% 6000/6000 [24:10<00:00,  4.14it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "QF1 = 65 QF2 = 90\n",
            "--------------------------------------------------------------------------------\n",
            "Test average MSE: 8.0191\n",
            "Test average normalised MSE: 0.0676\n",
            "Test accuracy: 0.1447\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Found 6000 images and 6000 labels in /content/Data/test.csv with filter (70, 90)\n",
            "Estimating Quantization Matrix: 100% 6000/6000 [24:06<00:00,  4.15it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "QF1 = 70 QF2 = 90\n",
            "--------------------------------------------------------------------------------\n",
            "Test average MSE: 5.0172\n",
            "Test average normalised MSE: 0.0586\n",
            "Test accuracy: 0.1954\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Found 6000 images and 6000 labels in /content/Data/test.csv with filter (75, 90)\n",
            "Estimating Quantization Matrix: 100% 6000/6000 [24:03<00:00,  4.16it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "QF1 = 75 QF2 = 90\n",
            "--------------------------------------------------------------------------------\n",
            "Test average MSE: 3.6162\n",
            "Test average normalised MSE: 0.0585\n",
            "Test accuracy: 0.2224\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Found 6000 images and 6000 labels in /content/Data/test.csv with filter (80, 90)\n",
            "Estimating Quantization Matrix: 100% 6000/6000 [24:03<00:00,  4.16it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "QF1 = 80 QF2 = 90\n",
            "--------------------------------------------------------------------------------\n",
            "Test average MSE: 3.4283\n",
            "Test average normalised MSE: 0.0918\n",
            "Test accuracy: 0.2253\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Found 6000 images and 6000 labels in /content/Data/test.csv with filter (85, 90)\n",
            "Estimating Quantization Matrix: 100% 6000/6000 [24:01<00:00,  4.16it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "QF1 = 85 QF2 = 90\n",
            "--------------------------------------------------------------------------------\n",
            "Test average MSE: 3.8104\n",
            "Test average normalised MSE: 0.1798\n",
            "Test accuracy: 0.2130\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Found 6000 images and 6000 labels in /content/Data/test.csv with filter (90, 90)\n",
            "Estimating Quantization Matrix:  62% 3733/6000 [14:54<09:12,  4.11it/s]"
          ]
        }
      ],
      "source": [
        "!python predict.py --model \"/content/model.hdf5\" --test_csv \"/content/Data/test.csv\" --rslt_dir \"/content/results/\" --max_q_coeffs 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLkKpzP1807c"
      },
      "outputs": [],
      "source": [
        " "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Primary Quantization-Third Quant Densenet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}