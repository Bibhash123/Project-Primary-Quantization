{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bibhash123/Project-Primary-Quantization/blob/main/experiments/primary_quantization_two_head_densenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d955f659",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:02.855188Z",
          "iopub.status.busy": "2022-03-07T14:14:02.853688Z",
          "iopub.status.idle": "2022-03-07T14:14:02.863029Z",
          "shell.execute_reply": "2022-03-07T14:14:02.862519Z",
          "shell.execute_reply.started": "2022-03-07T13:44:12.765007Z"
        },
        "papermill": {
          "duration": 0.027997,
          "end_time": "2022-03-07T14:14:02.863161",
          "exception": false,
          "start_time": "2022-03-07T14:14:02.835164",
          "status": "completed"
        },
        "tags": [],
        "id": "d955f659"
      },
      "outputs": [],
      "source": [
        "COLAB = False\n",
        "if COLAB:\n",
        "    DATA_DIR = \"/content/Data\"\n",
        "else:\n",
        "    DATA_DIR = \"../input/tondidataset/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f839dc6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:02.905015Z",
          "iopub.status.busy": "2022-03-07T14:14:02.904240Z",
          "iopub.status.idle": "2022-03-07T14:14:02.906103Z",
          "shell.execute_reply": "2022-03-07T14:14:02.906776Z",
          "shell.execute_reply.started": "2022-03-07T13:44:12.791993Z"
        },
        "papermill": {
          "duration": 0.029632,
          "end_time": "2022-03-07T14:14:02.906921",
          "exception": false,
          "start_time": "2022-03-07T14:14:02.877289",
          "status": "completed"
        },
        "tags": [],
        "id": "9f839dc6"
      },
      "outputs": [],
      "source": [
        "if COLAB:\n",
        "    from google.colab import files\n",
        "    _ = files.upload()\n",
        "    !mkdir ~/.kaggle/\n",
        "    !cp kaggle.json ~/.kaggle/kaggle.json\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    !pip install -q kaggle\n",
        "    !kaggle datasets download -d \"bibhash123/tondidataset\"\n",
        "    !unzip -q tondidataset.zip -d \"/content/Data/\"\n",
        "    !rm -r tondidataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9d48a11",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:02.938848Z",
          "iopub.status.busy": "2022-03-07T14:14:02.938295Z",
          "iopub.status.idle": "2022-03-07T14:14:08.515507Z",
          "shell.execute_reply": "2022-03-07T14:14:08.514532Z",
          "shell.execute_reply.started": "2022-03-07T13:44:12.808775Z"
        },
        "papermill": {
          "duration": 5.595169,
          "end_time": "2022-03-07T14:14:08.515658",
          "exception": false,
          "start_time": "2022-03-07T14:14:02.920489",
          "status": "completed"
        },
        "tags": [],
        "id": "b9d48a11"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gc\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc4de418",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:08.548399Z",
          "iopub.status.busy": "2022-03-07T14:14:08.547795Z",
          "iopub.status.idle": "2022-03-07T14:14:09.029832Z",
          "shell.execute_reply": "2022-03-07T14:14:09.028897Z",
          "shell.execute_reply.started": "2022-03-07T13:44:18.339806Z"
        },
        "papermill": {
          "duration": 0.500394,
          "end_time": "2022-03-07T14:14:09.030025",
          "exception": false,
          "start_time": "2022-03-07T14:14:08.529631",
          "status": "completed"
        },
        "tags": [],
        "id": "fc4de418"
      },
      "outputs": [],
      "source": [
        "train_files = pd.read_csv(os.path.join(DATA_DIR, \"mini_train.csv\"),sep=\";\",header=None,\n",
        "                         names=['idx', 'filenames', 'quality1', 'quality2', 'software', 'labels',\n",
        "                                'shift_r', 'shift_c','base_image']\n",
        "                         )\n",
        "trn,val = train_test_split(train_files,test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d6ebf56",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:09.063969Z",
          "iopub.status.busy": "2022-03-07T14:14:09.062018Z",
          "iopub.status.idle": "2022-03-07T14:14:09.066292Z",
          "shell.execute_reply": "2022-03-07T14:14:09.065839Z",
          "shell.execute_reply.started": "2022-03-07T13:44:19.296519Z"
        },
        "papermill": {
          "duration": 0.022276,
          "end_time": "2022-03-07T14:14:09.066397",
          "exception": false,
          "start_time": "2022-03-07T14:14:09.044121",
          "status": "completed"
        },
        "tags": [],
        "id": "5d6ebf56",
        "outputId": "293293a8-0802-49ef-eecd-91478a0033d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Shape:  (97200, 9)\n",
            "Validation Shape:  (10800, 9)\n"
          ]
        }
      ],
      "source": [
        "print(\"Train Shape: \", trn.shape)\n",
        "print(\"Validation Shape: \", val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05c03d4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:09.103142Z",
          "iopub.status.busy": "2022-03-07T14:14:09.102445Z",
          "iopub.status.idle": "2022-03-07T14:14:09.104587Z",
          "shell.execute_reply": "2022-03-07T14:14:09.104986Z",
          "shell.execute_reply.started": "2022-03-07T13:44:19.305784Z"
        },
        "papermill": {
          "duration": 0.024462,
          "end_time": "2022-03-07T14:14:09.105113",
          "exception": false,
          "start_time": "2022-03-07T14:14:09.080651",
          "status": "completed"
        },
        "tags": [],
        "id": "b05c03d4"
      },
      "outputs": [],
      "source": [
        "def preprocess_input(im_file, target_size, scale=255.):\n",
        "    \"\"\" \n",
        "        Read image and (eventually) scale data\n",
        "        Arguments:\n",
        "            im_file     : input image file\n",
        "            target_size : output size of the image (height, width)\n",
        "            scale       : pixel scaling value\n",
        "        Returns: The image\n",
        "    \"\"\"\n",
        "    file_bytes = tf.io.read_file(im_file)\n",
        "    img = tf.image.decode_png(file_bytes, channels = 0)\n",
        "    # Normalize and Resize\n",
        "#     if img.shape != target_size:\n",
        "#         img = tf.image.resize(img, target_size)\n",
        "    img = tf.cast(img, tf.float32)\n",
        "    return img\n",
        "  \n",
        "def string2Q(s, size=(8, 8), flatten=True):\n",
        "    \"\"\" Converts a comma separated string to a matrix.\n",
        "        Keyword arguments:\n",
        "        sq : input string\n",
        "        size : output matrix size\n",
        "    \"\"\"\n",
        "    if flatten:\n",
        "        return tf.strings.to_number(tf.strings.split(s,','),out_type=tf.int32)\n",
        "    else:\n",
        "        return tf.reshape(tf.strings.to_number(tf.strings.split(s,','),out_type=tf.int32),size)\n",
        "        \n",
        "def get_label(im_label):\n",
        "    return string2Q(im_label)[:15]\n",
        "\n",
        "def getQFRange(qf1):\n",
        "    return K.stack([qf1-5,qf1,qf1+5],axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08fbe083",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:09.145926Z",
          "iopub.status.busy": "2022-03-07T14:14:09.145232Z",
          "iopub.status.idle": "2022-03-07T14:14:09.147397Z",
          "shell.execute_reply": "2022-03-07T14:14:09.147790Z",
          "shell.execute_reply.started": "2022-03-07T13:44:19.317655Z"
        },
        "papermill": {
          "duration": 0.028633,
          "end_time": "2022-03-07T14:14:09.147923",
          "exception": false,
          "start_time": "2022-03-07T14:14:09.119290",
          "status": "completed"
        },
        "tags": [],
        "id": "08fbe083"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "QFS = [60,65,70,75,80,85,90,98]\n",
        "\n",
        "def build_decoder(is_labelled):\n",
        "    def if_labelled(path,label, target_size):\n",
        "        image = preprocess_input(path,target_size)\n",
        "        out_img = K.concatenate([tf.expand_dims(255.0*tf.image.adjust_jpeg_quality(image/255.0,qf),axis=0) for qf in QFS],axis=0)\n",
        "        label = get_label(label)\n",
        "        # qf = getQFRange(qf1)\n",
        "        return (image, out_img), label\n",
        "  \n",
        "    def not_labelled(path,target_size):\n",
        "        image = preprocess_input(path,target_size)\n",
        "        out_img = K.concatenate([tf.expand_dims(255.0*tf.image.adjust_jpeg_quality(image/255.0,qf),axis=0) for qf in QFS],axis=0)\n",
        "        return (image, out_img)    \n",
        "\n",
        "    return if_labelled if is_labelled else not_labelled\n",
        "\n",
        "\n",
        "def create_dataset(df, batch_size = 32, is_labelled = False, repeat = False, shuffle = False, batch=False, cache=False):\n",
        "    decode_fn = build_decoder(is_labelled)\n",
        "    df['filenames'] = df['filenames'].apply(lambda x: \"/\".join(x.split('/')[-3:]))\n",
        "    df['filenames'] = df['filenames'].apply(lambda x: os.path.join(DATA_DIR,x))\n",
        "    \n",
        "    # Create Dataset\n",
        "    if is_labelled:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((df['filenames'].values,df[\"labels\"].values))\n",
        "    else:\n",
        "        dataset = tf.data.Dataset.from_tensor_slices((df['filenames'].values))\n",
        "\n",
        "    dataset = dataset.map(partial(decode_fn,target_size=(64,64)), num_parallel_calls = AUTOTUNE)\n",
        "    dataset = dataset.cache(\"\") if cache else dataset\n",
        "    dataset = dataset.repeat() if repeat else dataset\n",
        "    dataset = dataset.shuffle(1024, reshuffle_each_iteration = True) if shuffle else dataset\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True) if batch else dataset\n",
        "    dataset = dataset.prefetch(AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "def getX(X,Y):\n",
        "    return X\n",
        "def getY(X,Y):\n",
        "    return Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73edf64e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:09.184566Z",
          "iopub.status.busy": "2022-03-07T14:14:09.182506Z",
          "iopub.status.idle": "2022-03-07T14:14:12.134087Z",
          "shell.execute_reply": "2022-03-07T14:14:12.133245Z",
          "shell.execute_reply.started": "2022-03-07T13:44:19.337923Z"
        },
        "papermill": {
          "duration": 2.972214,
          "end_time": "2022-03-07T14:14:12.134218",
          "exception": false,
          "start_time": "2022-03-07T14:14:09.162004",
          "status": "completed"
        },
        "tags": [],
        "id": "73edf64e",
        "outputId": "e1dce1f9-9bdf-49ac-84d9-6d8d8398f39c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "2022-03-07 14:14:09.481842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-07 14:14:09.575238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-07 14:14:09.575992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-07 14:14:09.580044: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-03-07 14:14:09.580888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-07 14:14:09.581897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-07 14:14:09.582849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-07 14:14:11.296947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-07 14:14:11.297796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-07 14:14:11.298521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-07 14:14:11.299120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
          ]
        }
      ],
      "source": [
        "train_set = create_dataset(trn, batch_size = 32, is_labelled = True, repeat = True, \n",
        "                          shuffle = True, batch=True,cache=False)\n",
        "val_set = create_dataset(val, batch_size = 32, is_labelled = True, repeat = False, \n",
        "                          shuffle = False, batch=True,cache=False)\n",
        "Y_val = val_set.map(getY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "246a008e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:12.175011Z",
          "iopub.status.busy": "2022-03-07T14:14:12.173468Z",
          "iopub.status.idle": "2022-03-07T14:14:12.175624Z",
          "shell.execute_reply": "2022-03-07T14:14:12.176054Z",
          "shell.execute_reply.started": "2022-03-07T13:44:22.333021Z"
        },
        "papermill": {
          "duration": 0.026881,
          "end_time": "2022-03-07T14:14:12.176178",
          "exception": false,
          "start_time": "2022-03-07T14:14:12.149297",
          "status": "completed"
        },
        "tags": [],
        "id": "246a008e"
      },
      "outputs": [],
      "source": [
        "class CrossAttention(L.Layer):\n",
        "    def __init__(self,input_dim, hidden_dim, output_dim):\n",
        "        super(CrossAttention,self).__init__()\n",
        "        self.w_k = self.add_weight(name='key', shape = (input_dim,hidden_dim), initializer=\"random_normal\", trainable=True)\n",
        "        self.w_q = self.add_weight(name='query', shape = (input_dim,hidden_dim), initializer=\"random_normal\", trainable=True)\n",
        "        self.w_v = self.add_weight(name='value', shape = (input_dim,output_dim), initializer=\"random_normal\", trainable=True)\n",
        "\n",
        "    def call(self,X1,X2):\n",
        "        dims = len(QFS)\n",
        "        key = tf.expand_dims(tf.matmul(X1,self.w_k),axis=1)\n",
        "        query = K.concatenate([tf.expand_dims(tf.matmul(X2[:,i,:],self.w_q),axis=2) for i in range(dims)],axis=2)\n",
        "        value = K.concatenate([tf.expand_dims(tf.matmul(X2[:,i,:],self.w_v),axis=2) for i in range(dims)],axis=2)\n",
        "        score = tf.matmul(tf.nn.softmax(tf.matmul(key,query),axis=-1),tf.transpose(value,perm=[0,2,1]))\n",
        "        return score[:,0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3770f87f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:12.217838Z",
          "iopub.status.busy": "2022-03-07T14:14:12.217332Z",
          "iopub.status.idle": "2022-03-07T14:14:17.880342Z",
          "shell.execute_reply": "2022-03-07T14:14:17.879872Z",
          "shell.execute_reply.started": "2022-03-07T13:44:22.347903Z"
        },
        "papermill": {
          "duration": 5.689397,
          "end_time": "2022-03-07T14:14:17.880466",
          "exception": false,
          "start_time": "2022-03-07T14:14:12.191069",
          "status": "completed"
        },
        "tags": [],
        "id": "3770f87f",
        "outputId": "0878b3ab-ba9a-4c6f-a794-82d8832b5938"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-07 14:14:12.980843: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TensorShape([1, 8, 8, 64])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class DCT(L.Layer):\n",
        "    def __init__(self):\n",
        "        super(DCT,self).__init__()\n",
        "        filters = []\n",
        "        for i in range(8):\n",
        "            for j in range(8):\n",
        "                f = []\n",
        "                k = 0.25*self.C(i)*self.C(j)\n",
        "                for x in range(8):\n",
        "                    f.append([k*np.cos(((2*x+1)*i*np.pi)/16) * np.cos(((2*y+1)*j*np.pi)/16) for y in range(8)])\n",
        "                filters.append(K.constant(np.stack(f,axis=0)))\n",
        "                \n",
        "        self.conv = L.Conv2D(64,(8,8),strides = 8,activation=None,use_bias=False,padding='same')\n",
        "        self.conv.build((64,64,1))\n",
        "        weights = self.conv.get_weights()\n",
        "        for i in range(64):\n",
        "            weights[0][:,:,0,i] = filters[i]\n",
        "        \n",
        "        self.conv.set_weights(weights)\n",
        "        self.trainable = False\n",
        "        self.conv.trainable = False\n",
        "        self.filters = filters\n",
        "        \n",
        "    def C(self,x):\n",
        "        if x==0:\n",
        "            return 1/(2**0.5)\n",
        "        elif x>0:\n",
        "            return 1\n",
        "    \n",
        "    def call(self,x):\n",
        "        h = self.conv(x)\n",
        "        return h\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0],input_shape[1]//8,input_shape[2]//8,64)\n",
        "\n",
        "from PIL import Image\n",
        "dct = DCT()\n",
        "inp = np.expand_dims(np.expand_dims(np.asarray(Image.open('../input/tondidataset/Train/60-90/00000024_rcb192c6at.TIF.png')),axis=-1),axis=0)\n",
        "inp = K.constant(inp.astype(float))\n",
        "dct_out = dct(inp)\n",
        "dct_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf0df7e5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:17.928383Z",
          "iopub.status.busy": "2022-03-07T14:14:17.927439Z",
          "iopub.status.idle": "2022-03-07T14:14:17.989866Z",
          "shell.execute_reply": "2022-03-07T14:14:17.990422Z",
          "shell.execute_reply.started": "2022-03-07T13:44:28.238741Z"
        },
        "papermill": {
          "duration": 0.094527,
          "end_time": "2022-03-07T14:14:17.990654",
          "exception": false,
          "start_time": "2022-03-07T14:14:17.896127",
          "status": "completed"
        },
        "tags": [],
        "id": "cf0df7e5",
        "outputId": "219e5fb6-ce33-492f-8939-5f58abc5a091"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([1, 20, 64, 1])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Histogram(L.Layer):\n",
        "    def __init__(self, b0,b1, num_bins, gamma):\n",
        "#         self.b0 = self.add_weight(name='b0', shape=[1], initializer=\"random_normal\", trainable=True)\n",
        "#         self.b1 = self.add_weight(name='b1', shape=[1], initializer=\"random_normal\", trainable=True)\n",
        "        super(Histogram,self).__init__()\n",
        "        self.b_ = np.linspace(b0,b1,num_bins)\n",
        "        self.gamma = gamma\n",
        "        self.avg_pool = L.AveragePooling2D(pool_size = (8,8), strides = 8)\n",
        "        self.diff_filter = np.array([[1,-1]]).reshape((2,1))\n",
        "        self.differentiator = L.Conv2D(1,(2,1),strides=1,activation=None, padding = 'same', use_bias = False)\n",
        "        self.differentiator.build((num_bins,64,1))\n",
        "        weights = self.differentiator.get_weights()\n",
        "        weights[0][:,:,0,0] = K.constant(self.diff_filter)\n",
        "        self.differentiator.set_weights(weights)\n",
        "        self.trainable = False\n",
        "        self.differentiator.trainable = False\n",
        "    \n",
        "    def call(self,X):\n",
        "        h = L.Reshape((64,64))(X)\n",
        "        matrix = [64**2 * K.mean(tf.nn.sigmoid(self.gamma*(h-b)),axis=1) for b in self.b_]\n",
        "#         matrix = [[64**2 * self.avg_pool(tf.expand_dims(tf.nn.sigmoid(self.gamma*(X[:,:,:,freq_pair]- b)),axis=-1))[:,0,0,0] \n",
        "#                    for freq_pair in range(64)] for b in self.b_]\n",
        "#         matrix = tf.expand_dims(tf.transpose(K.stack(matrix,axis=0), perm=[2,0,1]),axis=-1)\n",
        "        matrix = tf.expand_dims(tf.transpose(K.stack(matrix,axis=0), perm=[1,0,2]),axis=-1)\n",
        "\n",
        "        return self.differentiator(matrix)\n",
        "    \n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (input_shape[0],len(self.b_),64,1)\n",
        "    \n",
        "hist = Histogram(-200,200,20,1e5)\n",
        "hist_out = hist(dct_out)\n",
        "hist_out.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28c10263",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:18.034327Z",
          "iopub.status.busy": "2022-03-07T14:14:18.033492Z",
          "iopub.status.idle": "2022-03-07T14:14:18.035305Z",
          "shell.execute_reply": "2022-03-07T14:14:18.035692Z",
          "shell.execute_reply.started": "2022-03-07T13:44:28.319026Z"
        },
        "papermill": {
          "duration": 0.029264,
          "end_time": "2022-03-07T14:14:18.035803",
          "exception": false,
          "start_time": "2022-03-07T14:14:18.006539",
          "status": "completed"
        },
        "tags": [],
        "id": "28c10263"
      },
      "outputs": [],
      "source": [
        "class ConvModel(tf.keras.models.Model):\n",
        "    def __init__(self,num_classes=10):\n",
        "        super(ConvModel,self).__init__()\n",
        "        self.n_classes = num_classes\n",
        "        self.block1 = L.Conv2D(16,(3,3),strides=1,input_shape=(None,20,64,1))\n",
        "\n",
        "        self.block2 = tf.keras.models.Sequential([\n",
        "                                                  L.Conv2D(16,(3,3),strides=1),\n",
        "                                                  L.BatchNormalization(),\n",
        "                                                  L.Activation('relu')\n",
        "        ])\n",
        "        self.block3 = tf.keras.models.Sequential([\n",
        "                                                 L.Conv2D(32,(3,3),strides=1),\n",
        "                                                 L.BatchNormalization(),\n",
        "                                                 L.Activation('relu')\n",
        "        ])\n",
        "        self.block4 = tf.keras.models.Sequential([\n",
        "                                                 L.Conv2D(64,(3,3),strides=1),\n",
        "                                                 L.BatchNormalization(),\n",
        "                                                 L.Activation('relu')\n",
        "        ])\n",
        "        self.block5 = tf.keras.models.Sequential([\n",
        "                                                 L.Conv2D(128,(1,1),strides=1),\n",
        "                                                 L.BatchNormalization(),\n",
        "                                                 L.Activation('relu'),\n",
        "                                                 L.AveragePooling2D(pool_size=(2,2),strides=2)\n",
        "        ])\n",
        "        \n",
        "        self.flatten = L.Flatten()\n",
        "        self.fc1 = L.Dense(200, activation='relu')\n",
        "        self.fc2 = L.Dense(100, activation='relu')\n",
        "#         self.fc3 = L.Dense(num_classes,activation=\"linear\")\n",
        "\n",
        "    def call(self,inputs,**kwargs):\n",
        "        out = self.block1(inputs)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.block4(out)\n",
        "        out = self.block5(out)\n",
        "\n",
        "        out = self.flatten(out)\n",
        "\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "#         out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "    def compute_output_shape(self,input_shape):\n",
        "        return (input_shape[0],100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d22b7a0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:18.077526Z",
          "iopub.status.busy": "2022-03-07T14:14:18.072693Z",
          "iopub.status.idle": "2022-03-07T14:14:19.625885Z",
          "shell.execute_reply": "2022-03-07T14:14:19.626633Z",
          "shell.execute_reply.started": "2022-03-07T13:44:45.195104Z"
        },
        "papermill": {
          "duration": 1.575569,
          "end_time": "2022-03-07T14:14:19.626799",
          "exception": false,
          "start_time": "2022-03-07T14:14:18.051230",
          "status": "completed"
        },
        "tags": [],
        "id": "2d22b7a0",
        "outputId": "e51fa5db-c344-448f-ad5f-0f31626d6b5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating DenseNet\n",
            "#############################################\n",
            "Dense blocks: 3\n",
            "Layers per dense block: [4, 4, 4]\n",
            "#############################################\n",
            "Creating DenseNet\n",
            "#############################################\n",
            "Dense blocks: 3\n",
            "Layers per dense block: [4, 4, 4]\n",
            "#############################################\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 64, 64, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 8, 64, 64, 1 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dct (DCT)                       (None, 8, 8, 64)     4096        input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, 8, 8, 8, 64)  4096        input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "histogram (Histogram)           (None, 20, 64, 1)    2           dct[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 8, 20, 64, 1) 2           time_distributed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Functional)            (None, 168)          142200      histogram[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_2 (TimeDistrib (None, 8, 168)       142200      time_distributed_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 168)          0           model_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 8, 168)       0           time_distributed_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           10816       flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_4 (TimeDistrib (None, 8, 64)        10816       time_distributed_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "cross_attention (CrossAttention (None, 64)           8192        dense_3[0][0]                    \n",
            "                                                                 time_distributed_4[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 15)           975         cross_attention[0][0]            \n",
            "==================================================================================================\n",
            "Total params: 323,395\n",
            "Trainable params: 309,439\n",
            "Non-trainable params: 13,956\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from densenet import DenseNet, ConvConst\n",
        "K.clear_session()\n",
        "with tf.device('/GPU:0'):\n",
        "#     err_model = ConvModel(num_classes = 15)\n",
        "    err_model,_ = DenseNet(input_shape = (20,64,1), nb_classes = 15, depth=18)\n",
        "    err_model = tf.keras.Model(inputs=err_model.input, outputs = err_model.layers[-2].output)\n",
        "#     err_model = tf.keras.applications.resnet50.ResNet50(include_top=False, weights=None, input_shape=(64,64,1))\n",
        "#     img_model = ConvModel(num_classes = 15)\n",
        "    img_model,_ = DenseNet(input_shape = (20,64,1), nb_classes = 15, depth=18)\n",
        "    img_model = tf.keras.Model(inputs=img_model.input, outputs = img_model.layers[-2].output)\n",
        "#     img_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False, weights=None, input_shape=(64,64,1))\n",
        "\n",
        "    inp1 = L.Input(shape=(64,64,1))\n",
        "    inp2 = L.Input(shape=(len(QFS),64,64,1))\n",
        "    h1 = DCT()(inp1)\n",
        "    h1 = Histogram(-200,200,20,1e5)(h1)\n",
        "    h1 = img_model(h1)\n",
        "    \n",
        "    h2 = L.TimeDistributed(DCT())(inp2)\n",
        "    h2 = L.TimeDistributed(Histogram(-200,200,20,1e5))(h2)\n",
        "    h2 = L.TimeDistributed(err_model)(h2)\n",
        "    h2 = L.TimeDistributed(L.Flatten())(h2)\n",
        "    h2 = L.TimeDistributed(L.Dense(64,activation='relu'))(h2)\n",
        "    h1 = L.Flatten()(h1)\n",
        "    h1 = L.Dense(64,activation='relu')(h1)\n",
        "    \n",
        "    h = CrossAttention(64,32,64)(h1,h2)\n",
        "    h = L.Dense(15,activation='linear')(h)\n",
        "    \n",
        "    model = tf.keras.Model(inputs = [inp1,inp2],\n",
        "                         outputs = h)\n",
        "    \n",
        "#     schedule = tf.keras.optimizers.schedules.ExponentialDecay(1e-4,\n",
        "#                                                               decay_steps=9000,\n",
        "#                                                               decay_rate=0.96,\n",
        "#                                                               staircase=True)\n",
        "    \n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-5, clipnorm = 1.0)\n",
        "    model.compile(loss = tf.keras.losses.LogCosh(), optimizer = opt)\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c96fd7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:19.664877Z",
          "iopub.status.busy": "2022-03-07T14:14:19.664269Z",
          "iopub.status.idle": "2022-03-07T14:14:19.667000Z",
          "shell.execute_reply": "2022-03-07T14:14:19.666556Z",
          "shell.execute_reply.started": "2022-03-07T13:44:48.919573Z"
        },
        "papermill": {
          "duration": 0.023433,
          "end_time": "2022-03-07T14:14:19.667125",
          "exception": false,
          "start_time": "2022-03-07T14:14:19.643692",
          "status": "completed"
        },
        "tags": [],
        "id": "20c96fd7"
      },
      "outputs": [],
      "source": [
        "class Logger(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_begin(self,epoch,logs={}):\n",
        "        print(\" Learning Rate: {}\".format(self.model.optimizer._decayed_lr(tf.float32).numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9ca0ce1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:19.708627Z",
          "iopub.status.busy": "2022-03-07T14:14:19.707835Z",
          "iopub.status.idle": "2022-03-07T14:14:19.713099Z",
          "shell.execute_reply": "2022-03-07T14:14:19.712649Z",
          "shell.execute_reply.started": "2022-03-07T13:44:49.0991Z"
        },
        "papermill": {
          "duration": 0.029117,
          "end_time": "2022-03-07T14:14:19.713207",
          "exception": false,
          "start_time": "2022-03-07T14:14:19.684090",
          "status": "completed"
        },
        "tags": [],
        "id": "a9ca0ce1"
      },
      "outputs": [],
      "source": [
        "class ConstWeight(tf.keras.callbacks.Callback):\n",
        "    def on_batch_end(self,epoch,logs={}):\n",
        "        weights = self.model.layers[2].layers[0].get_weights()\n",
        "        weights[0][2,2,0,:] = np.zeros((12,))\n",
        "        for i in range(weights[0].shape[-1]):\n",
        "            t = weights[0][:,:,0,i]\n",
        "            nom = -1*np.sum(t)\n",
        "            weights[0][:,:,:,i] = weights[0][:,:,:,i]/nom\n",
        "        weights[0][2,2,0,:] = np.ones((12,))  \n",
        "        self.model.layers[2].layers[0].set_weights(weights)\n",
        "\n",
        "        weights = self.model.layers[3].model.layers[0].get_weights()\n",
        "        weights[0][2,2,0,:] = np.zeros((12,))\n",
        "        for i in range(weights[0].shape[-1]):\n",
        "            t = weights[0][:,:,0,i]\n",
        "            nom = -1*np.sum(t)\n",
        "            weights[0][:,:,:,i] = weights[0][:,:,:,i]/nom\n",
        "        weights[0][2,2,0,:] = np.ones((12,))  \n",
        "        self.model.layers[3].model.layers[0].set_weights(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dff0c6bc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T14:14:19.754188Z",
          "iopub.status.busy": "2022-03-07T14:14:19.753373Z",
          "iopub.status.idle": "2022-03-07T18:17:23.092534Z",
          "shell.execute_reply": "2022-03-07T18:17:23.091616Z"
        },
        "papermill": {
          "duration": 14583.363067,
          "end_time": "2022-03-07T18:17:23.092686",
          "exception": false,
          "start_time": "2022-03-07T14:14:19.729619",
          "status": "completed"
        },
        "tags": [],
        "id": "dff0c6bc",
        "outputId": "1338f766-62a6-4fef-f34b-1dd42b52133a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-03-07 14:14:28.096594: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3037/3037 [==============================] - 409s 130ms/step - loss: 3.7995 - val_loss: 3.0000\n",
            "Epoch 2/60\n",
            "3037/3037 [==============================] - 393s 129ms/step - loss: 2.8721 - val_loss: 2.7316\n",
            "Epoch 3/60\n",
            "3037/3037 [==============================] - 389s 128ms/step - loss: 2.6275 - val_loss: 2.8370\n",
            "Epoch 4/60\n",
            "3037/3037 [==============================] - 388s 128ms/step - loss: 2.5456 - val_loss: 2.5757\n",
            "Epoch 5/60\n",
            "3037/3037 [==============================] - 395s 130ms/step - loss: 2.4983 - val_loss: 2.7911\n",
            "Epoch 6/60\n",
            "3037/3037 [==============================] - 398s 131ms/step - loss: 2.4492 - val_loss: 2.6576\n",
            "Epoch 7/60\n",
            "3037/3037 [==============================] - 397s 131ms/step - loss: 2.4149 - val_loss: 2.9895\n",
            "Epoch 8/60\n",
            "3037/3037 [==============================] - 392s 129ms/step - loss: 2.3772 - val_loss: 2.5285\n",
            "Epoch 9/60\n",
            "3037/3037 [==============================] - 386s 127ms/step - loss: 2.3398 - val_loss: 3.4206\n",
            "Epoch 10/60\n",
            "3037/3037 [==============================] - 396s 130ms/step - loss: 2.3070 - val_loss: 2.4568\n",
            "Epoch 11/60\n",
            "3037/3037 [==============================] - 395s 130ms/step - loss: 2.2853 - val_loss: 2.5197\n",
            "Epoch 12/60\n",
            "3037/3037 [==============================] - 390s 128ms/step - loss: 2.2581 - val_loss: 2.6727\n",
            "Epoch 13/60\n",
            "3037/3037 [==============================] - 390s 128ms/step - loss: 2.2361 - val_loss: 3.2598\n",
            "Epoch 14/60\n",
            "3037/3037 [==============================] - 387s 128ms/step - loss: 2.2195 - val_loss: 2.2473\n",
            "Epoch 15/60\n",
            "3037/3037 [==============================] - 390s 128ms/step - loss: 2.2006 - val_loss: 2.5726\n",
            "Epoch 16/60\n",
            "3037/3037 [==============================] - 390s 129ms/step - loss: 2.1813 - val_loss: 2.9010\n",
            "Epoch 17/60\n",
            "3037/3037 [==============================] - 397s 131ms/step - loss: 2.1663 - val_loss: 2.1824\n",
            "Epoch 18/60\n",
            "3037/3037 [==============================] - 402s 132ms/step - loss: 2.1502 - val_loss: 2.8011\n",
            "Epoch 19/60\n",
            "3037/3037 [==============================] - 390s 128ms/step - loss: 2.1379 - val_loss: 3.9209\n",
            "Epoch 20/60\n",
            "3037/3037 [==============================] - 396s 131ms/step - loss: 2.1203 - val_loss: 2.7972\n",
            "Epoch 21/60\n",
            "3037/3037 [==============================] - 396s 131ms/step - loss: 2.1070 - val_loss: 2.1660\n",
            "Epoch 22/60\n",
            "3037/3037 [==============================] - 393s 129ms/step - loss: 2.0937 - val_loss: 2.5892\n",
            "Epoch 23/60\n",
            "3037/3037 [==============================] - 399s 131ms/step - loss: 2.0870 - val_loss: 2.8986\n",
            "Epoch 24/60\n",
            "3037/3037 [==============================] - 387s 127ms/step - loss: 2.0698 - val_loss: 2.1850\n",
            "Epoch 25/60\n",
            "3037/3037 [==============================] - 394s 130ms/step - loss: 2.0577 - val_loss: 2.5445\n",
            "Epoch 26/60\n",
            "3037/3037 [==============================] - 389s 128ms/step - loss: 2.0474 - val_loss: 2.0889\n",
            "Epoch 27/60\n",
            "3037/3037 [==============================] - 398s 131ms/step - loss: 2.0358 - val_loss: 2.2795\n",
            "Epoch 28/60\n",
            "3037/3037 [==============================] - 401s 132ms/step - loss: 2.0250 - val_loss: 2.7443\n",
            "Epoch 29/60\n",
            "3037/3037 [==============================] - 389s 128ms/step - loss: 2.0174 - val_loss: 2.4777\n",
            "Epoch 30/60\n",
            "3037/3037 [==============================] - 396s 130ms/step - loss: 2.0105 - val_loss: 2.0808\n",
            "Epoch 31/60\n",
            "3037/3037 [==============================] - 397s 131ms/step - loss: 1.9961 - val_loss: 3.2785\n",
            "Epoch 32/60\n",
            "3037/3037 [==============================] - 389s 128ms/step - loss: 1.9924 - val_loss: 2.9817\n",
            "Epoch 33/60\n",
            "3037/3037 [==============================] - 397s 131ms/step - loss: 1.9816 - val_loss: 2.3281\n",
            "Epoch 34/60\n",
            "3037/3037 [==============================] - 390s 128ms/step - loss: 1.9788 - val_loss: 2.3097\n",
            "Epoch 35/60\n",
            "3037/3037 [==============================] - 389s 128ms/step - loss: 1.9697 - val_loss: 2.9259\n",
            "Epoch 36/60\n",
            "3037/3037 [==============================] - 397s 131ms/step - loss: 1.9595 - val_loss: 2.3479\n",
            "Epoch 37/60\n",
            "3037/3037 [==============================] - 389s 128ms/step - loss: 1.9535 - val_loss: 3.5077\n",
            "[INFO] Obtaining Predictions\n"
          ]
        }
      ],
      "source": [
        "ckpt = tf.keras.callbacks.ModelCheckpoint('model.hdf5', monitor = 'val_loss', mode='min',\n",
        "                                          save_best_only = True, save_weights_only = True)\n",
        "es = tf.keras.callbacks.EarlyStopping(patience = 7, monitor = 'val_loss', mode='min',\n",
        "                                      restore_best_weights=True)\n",
        "logger = Logger()\n",
        "# const = ConstWeight()\n",
        "try:\n",
        "    # model.load_weights('last_trained.hdf5')\n",
        "    model.fit(train_set,\n",
        "            epochs = 60,\n",
        "            steps_per_epoch = (trn.shape[0]//32),\n",
        "            validation_data = val_set,\n",
        "            callbacks = [ckpt,es],\n",
        "            initial_epoch=0\n",
        "            )\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n[INFO] Interrupted Training\")\n",
        "    model.save_weights('last_trained.hdf5')\n",
        "print('[INFO] Obtaining Predictions')\n",
        "model.load_weights('model.hdf5')\n",
        "pred = model.predict(val_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e39f8dd1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T18:18:23.410890Z",
          "iopub.status.busy": "2022-03-07T18:18:23.409573Z",
          "iopub.status.idle": "2022-03-07T18:18:24.389868Z",
          "shell.execute_reply": "2022-03-07T18:18:24.389384Z"
        },
        "papermill": {
          "duration": 31.395716,
          "end_time": "2022-03-07T18:18:24.390039",
          "exception": false,
          "start_time": "2022-03-07T18:17:52.994323",
          "status": "completed"
        },
        "tags": [],
        "id": "e39f8dd1"
      },
      "outputs": [],
      "source": [
        "a = list(train_set.take(1).as_numpy_iterator())[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a6930f4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T18:19:24.942557Z",
          "iopub.status.busy": "2022-03-07T18:19:24.941655Z",
          "iopub.status.idle": "2022-03-07T18:19:24.945324Z",
          "shell.execute_reply": "2022-03-07T18:19:24.944683Z"
        },
        "papermill": {
          "duration": 30.368179,
          "end_time": "2022-03-07T18:19:24.945477",
          "exception": false,
          "start_time": "2022-03-07T18:18:54.577298",
          "status": "completed"
        },
        "tags": [],
        "id": "6a6930f4",
        "outputId": "45b7e451-ee63-4bcd-a72a-08b9413596fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(32, 64, 64, 1)\n",
            "(32, 8, 64, 64, 1)\n",
            "(32, 15)\n"
          ]
        }
      ],
      "source": [
        "print(a[0][0].shape)\n",
        "print(a[0][1].shape)\n",
        "print(a[1].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a329b758",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-07T18:20:25.321335Z",
          "iopub.status.busy": "2022-03-07T18:20:25.320521Z",
          "iopub.status.idle": "2022-03-07T18:20:34.697321Z",
          "shell.execute_reply": "2022-03-07T18:20:34.698040Z"
        },
        "papermill": {
          "duration": 39.763431,
          "end_time": "2022-03-07T18:20:34.698196",
          "exception": false,
          "start_time": "2022-03-07T18:19:54.934765",
          "status": "completed"
        },
        "tags": [],
        "id": "a329b758"
      },
      "outputs": [],
      "source": [
        "y = np.array(list(Y_val.unbatch().as_numpy_iterator()))\n",
        "print(\"Shape Y: \",y.shape)\n",
        "print(\"Accuracy = {:.4f}\".format(np.sum(np.round(pred)==y)/(15*y.shape[0])))\n",
        "print(\"MSE = {:.4f}\".format(np.sum(np.square(y - pred)) / (y.shape[0]*15)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dec9d50",
      "metadata": {
        "papermill": {
          "duration": 30.070132,
          "end_time": "2022-03-07T18:21:35.253394",
          "exception": false,
          "start_time": "2022-03-07T18:21:05.183262",
          "status": "completed"
        },
        "tags": [],
        "id": "6dec9d50"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 14894.582888,
      "end_time": "2022-03-07T18:22:09.428817",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2022-03-07T14:13:54.845929",
      "version": "2.3.3"
    },
    "colab": {
      "name": "primary-quantization-two-head-densenet.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}